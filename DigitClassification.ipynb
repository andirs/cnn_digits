{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNs for Digits Classification\n",
    "This is a quick introduction into how to set up a Convolutional Neural Network to classify hand-drawn digits. Before getting started, I wanted to collect an unique set of data rather than relying to experience with the up- and downsides of \"not-battle-tested\" data. \n",
    "\n",
    "In order to do so, I created a (read modified an existing) JavaScript/HTML5 app and drew digits myself.\n",
    "\n",
    "The resulting model and website including a quick summary of all steps as well as an interactive front-end can be found [here](http://digits.rvbin.com). The dataset created for this model can be found [here](https://drive.google.com/open?id=1J1G1jK8hotALkZZWR07fTjrGfZvLkH2y)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "To make the images usable for any CNN model, it is helpful to transform the information into arrays. We'll feed those number arrays into our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import os, sys\n",
    "import scipy\n",
    "import skimage.transform as sktransform\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from collections import Counter\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "random_state = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1_image_13.png', '8_image_0.jpg']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PREP_PATH = \"images/prep/\"\n",
    "os.listdir('images/prep/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = '1_image_13.png'\n",
    "test_img2 = '8_image_0.jpg'\n",
    "path = PREP_PATH + test_img\n",
    "path2 = PREP_PATH + test_img2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in images\n",
    "Let's see how a test image looks like. `PIL` offers some easy accesible functions to handle image data even in jupyter notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_turn_to_array(path):\n",
    "    png = Image.open(path)\n",
    "    png.load()\n",
    "    return np.array(png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image1 = load_and_turn_to_array(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images have 4 channels and 256 x 256 pixels per channel. While the first 3 channels contain color information, the fourth dimension stores opacity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc26138b898>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_image1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this dataset deals with strictly black and white images, the alpha channel contains enough information for us to move forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_only_alpha_channel(img):\n",
    "    return img[:,:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_alpha = grab_only_alpha_channel(test_image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.imshow(only_alpha, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Values\n",
    "To make it easier for the gradients to find a minimum and progress faster, it is helpful to normalize the pixel values and range them inbetween 0 to 1. This can be achieved by simply dividing all values by 255, it's maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(img):\n",
    "    img = img / 255.\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_alpha = normalize_image(only_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.imshow(normalized_alpha, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I handcrafted 101 images of every digit, to prepare a training and testing set. All these beauties are stored in the folder `images/digits/`. To download the images and reproduce the work in here, head over [here](https://drive.google.com/open?id=1J1G1jK8hotALkZZWR07fTjrGfZvLkH2y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIGITS_IMAGE_PATH = 'images/digits/'\n",
    "\n",
    "def count_all_images(path):\n",
    "    counter = 0\n",
    "    for folder_name in os.listdir(path):\n",
    "        if folder_name in [str(x) for x in range(10)]:  # if foldername is a number from 0 to 9\n",
    "            for image_name in os.listdir(path + folder_name):\n",
    "                if 'png' in image_name:\n",
    "                    counter += 1\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1010 images in all folders\n"
     ]
    }
   ],
   "source": [
    "img_count = count_all_images(DIGITS_IMAGE_PATH)\n",
    "print (\"There are {} images in all folders\".format(img_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use those, we're going to read them in, and store them in numpy arrays. Those will come in handy when we're building our model later on. I'll go over the steps in a bit but for now, the summary of the ```generate_X_and_y``` function is: Read in all data, create a Y and X vetor, turn those images into arrays and store them in the proper format.\n",
    "\n",
    "> We'll hold on to the channel information - while it wouldn't be needed this format has evolved as a standard to deal with more complex information in i.e. RGB(A) format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_X_and_y(path, shape=(256, 256)):\n",
    "    img_count = count_all_images(path)\n",
    "    y_vect = np.zeros(shape=(img_count, 10))  # create empty vector for labels\n",
    "    X_vect = np.zeros(shape=(img_count, shape[0], shape[1], 1))  # create empty vector for images\n",
    "    counter = 0\n",
    "    for folder_name in os.listdir(path):\n",
    "        if folder_name in [str(x) for x in range(10)]:  # if foldername is a number from 0 to 9\n",
    "            # access folder\n",
    "            for file_name in os.listdir(path + folder_name):\n",
    "                if \"png\" in file_name:\n",
    "                    clear_output(wait=True)\n",
    "                    print (\"Working on image number {} (Label:  {} || Filename: {})\".format(\n",
    "                        counter, folder_name, file_name))\n",
    "                    tmp_img = load_and_turn_to_array(path + folder_name + '/' + file_name)\n",
    "                    tmp_img = grab_only_alpha_channel(tmp_img)\n",
    "                    y_tmp = np.zeros(shape=(10), dtype=int)\n",
    "                    y_tmp[int(folder_name)] = 1\n",
    "                    y_vect[counter] = y_tmp\n",
    "                    X_vect[counter, :, :, 0] = tmp_img\n",
    "                    counter += 1\n",
    "    return X_vect, y_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on image number 1009 (Label:  9 || Filename: 9_image_72.png)\n"
     ]
    }
   ],
   "source": [
    "X_all, Y_all = generate_X_and_y(DIGITS_IMAGE_PATH, shape=(256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1010, 256, 256, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_all, Y_all, test_size=.4, stratify=Y_all, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev, X_test, Y_dev, Y_test = train_test_split(\n",
    "    X_test, Y_test, test_size=.5, stratify=Y_test, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Images on a case-by-case basis\n",
    "To help with the display of images we craft a swifty function, that displays any given number in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_number_and_image(X, Y, image_number):\n",
    "    plt.imshow(X[image_number, :, :, 0], cmap='gray')\n",
    "    plt.show()\n",
    "    print (\"Label: {}\".format(Y[image_number]))\n",
    "    return Y[image_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAFYhJREFUeJzt3X+MVPW5x/H346psAm13LcVy3dWF1puKNGyRIk0bSrUi2h/SX4itFG5qaRqb1IabXGpNNG1ua61i0wSbUqX4o5SKWIXEqmhcmtaKXdvlhyiVInQXxbVZdtVrFl147h9zlg4clvnO7pw5Z2Y+r+RkZ84+wz6Ou598z/ec8x1zd0RE8p2UdgMikj0KBhGJUTCISIyCQURiFAwiEqNgEJGYxILBzOaY2U4z22VmS5P6OSJSepbEdQxmVgf8HbgI6AL+Alzh7jtK/sNEpOSSGjFMB3a5+253fwtYA1yW0M8SkRI7OaF/9wygM+95F3D+UMVmpssvRZL3L3d/T0hhUsFQkJktBhan9fNFatDe0MKkgmEf0Jz3vCnad4S7rwBWgEYMIlmT1BzDX4CzzWyCmZ0KzAfWJ/SzRKTEEhkxuPuAmX0LeASoA1a6+7NJ/CwRKb1ETlcW3YQOJUTK4Rl3nxZSqCsfRSRGwSAiMQoGEYlRMIhIjIJBRGIUDCISo2AQkRgFg4jEKBhEJEbBICIxCgYRiVEwiEiMgkFEYhQMIhKjYBCRGAWDiMQoGEQkRsEgIjEKBhGJUTCISIyCQURiFAwiEqNgEJEYBYOIxCgYRCRGwSAiMQoGEYlRMIhIjIJBRGIUDCISo2AQkZiT025A0tfa2sq73vWuI89nzZp11PcbGhpobW098nzy5MmMHTu2XO1VnN7eXhobG9NuY0QUDFWmpaWFs84668jzwT/ylpYWWlpaAGhqauL9739/Ct3VhoaGBg4cOEBrayt79+5Nu51hMXdPuwfMLP0mMmrTpk3MnDkz7TZkGDI4cnjG3aeFFI5ojsHM9pjZNjPrMLP2aN9pZrbRzF6IvmbqnakUkydP5u2331YoVLCGhgZuv/32tNsYlhGNGMxsDzDN3f+Vt+8moMfdbzSzpUCju/9PgX9HI4ZjDAwMUFdXl3YbMkJ9fX00NDSk3cag8owYhnAZcGf0+E5gbgI/o6pt2rRJoVAl3vnOd6bdwrCMdMTwInAAcOAX7r7CzHrdvSH6vgEHBp8f89rFwOLo6XnDbqIKZWHeR0on92eQCcEjhpGelfiYu+8zs3HARjN7Pv+b7u5DHSa4+wpgBehQQqpXpYb8iA4l3H1f9LUb+B0wHXjFzMYDRF+7R9pkrTl06FDaLUiJvPbaa2m3MCzDDgYzG21m7xh8DMwGtgPrgYVR2ULgwZE2WWv+9Kc/pd2ClMhDDz2UdgvDMuw5BjObSG6UALlDktXu/r9m9m7gXuBMYC8wz917CvxblTneSpDOSlSHCRMmsGfPnrTbGBQ8x6ALnDJq8uTJdHR0lCUcDhw4wNatW4887+jooLe396iatra2I497e3vp6OhIvK+s2rZtG5MnTy5Yt337dj74wQ+WoaNgZZt8lIRs376dk0/W/56sWb16dVAoAHzmM59JuJvkaMQgUoT+/n5GjRpVsG7Lli1H3XiWEale4CRSlebOnRsUCgCrVq1KtpmEKRhEAl1zzTXBtQ888ECCnSRPhxIiAVpaWnjxxReD6zN0tWM+HUqIlNLf/va34NpquEBNwSASoJg7JO+9994EOykPBYNIid10001ptzBiCgaRAo5dA/NENm3aVBUXfykYRApYtGhRcG2ln6YcpLMSIidQzNmIvXv3HllwN6N0VkKkFIo5LCjmkCPrFAwiQ1i0aNFRn7dxInfeeWeW7qIcMQWDyBBqcW5hkIJB5DhaW1v5+Mc/HlS7ZcuWo25LrwYKBpHjuO6664Jrf/rTnybYSTp0VkLkGIMfMReir6+PlpaW2MI2GaWzEiLDMXr0aF599dXg+tbW1koJhaIoGETyLFmypKiVs6rpTEQ+HUqI5Hn99dcZM2ZMcH1Gb68eig4lRIajmFAYGBhIsJN0KRhEImPHji2qfs2aNQl1kj4Fg0jk2muvDa4dGBjg61//eoLdpEvBIAIsX76c73znO0G1+/fvZ/To0fT39yfcVXoUDFLzmpubueqqq4Lrr7/+et56660EO0qfgkFq3g033MCpp54aVNvZ2ckdd9yRcEfpUzBITZs4cSILFy4sXBi57rrrqmKx10IUDFLTfvCDHwR/Puju3bu55557Eu4oG/ThiFKz1q1bx+c///mg2ueff55zzjkn4Y6yQ1c+Ss0q5nd/7ty5PPjggwl2UxbBVz4qGKRmFfO7X2GXPg9Fl0SLnMj06dPTbiHTFAxSk374wx8G1z799NMJdpJR7n7CDVgJdAPb8/adBmwEXoi+Nkb7DfgZsAvYCkwt9O9Hr3Nt2sq1zZw504sxc+bM1Hsu0dYe8vfo7oT80c4EpnJ0MNwELI0eLwV+HD2+FPg9uYCYAWxWMGjL0jZnzpyiQmH69Omp91zCrXTBEP3htnB0MOwExkePxwM7o8e/AK44Xp2CQVsWto6OjuBQ2LBhQ+r9lngLDobhzjGc7u4vR4/3A6dHj88AOvPquqJ9IqmbO3cuU6ZMCa4vZkHYajPiC5zc3YdzutHMFgOLR/rzRUL96Ec/Cq5dt24dW7ZsSbCbbBvuiOEVMxsPEH3tjvbvA5rz6pqifTHuvsLdp3ngeVWRkbj88sv5wAc+EFR7+PDhmh4twPCDYT2wMHq8EHgwb/9XLWcG0Jd3yCGSipNOOqmo05OrV6/m+eefT7CjChAwMfgb4GXgbXJzBl8D3g08Tu505WPAaf7v05XLgX8A24BpgZObaU/KaKvi7Z///GfwhOPtt9+eer8JbsGTj7okWqpeMb/jZ555Jp2dnYULK5MuiRYBghdgGVTFoVAUBYNUtSVLlgTXVvMajsVSMEjVqq+v5/vf/35w/W233ZZgN5VFwSBVa/ny5cEfN/fmm28WdZ1DtdPko1Sl6dOns3nz5qDavr4+zjrrLPr6+hLuKnWafJTa9uUvfzm4dtmyZbUQCkXRiEGqjpmxf/9+xo0bV7B2YGCAxsZG3njjjTJ0ljqNGKR2XXDBBUGhAPDwww/XSigURcEgVefKK68Mrv3mN7+ZYCeVS8EgVeXyyy9n0aJFQbVXXXUVXV1dyTZUoRQMUlWKGS389re/TbCTyqbJR6kajY2NvPrqq8GfLFUlS8IXQ5OPUnvmz58fHApyYgoGqRoLFiwIrj1w4ECCnVQ+BYNUjY985CPBtZpfODHNMUjVCP1d7urqorm5uXBh9dEcg9SWYj5ybtWqVck1UiUUDFIVijlN+atf/SrBTqqDgkEqXl1dXXAwPPPMM+zevTvhjiqfgkEq3uzZs2lsbAyqveeeexLupjooGKTihY4WDh06xOrVqxPupjooGKSiLViwIHjthUWLFtHd3V24UBQMUtlCRwv9/f3cd999CXdTPRQMUrHGjRvHhRdeGFR7//33axXoIigYpGJ95StfCb43QpOOxVEwSMUKPYzo7u7m0UcfTbib6qJgkIo0ceJEpk6dGlS7Zs0aDh06lHBH1UX3SkhF6uzspKmpKai2BtddGIrulZDqFhoKMjwKBhGJUTBIxTnllFOCa5988skEO6leCgapOJ/61KeCa3Wacng0+SgVZcyYMfT09ASNGjZs2MBnP/vZMnRVMTT5KNVp/vz5wYcSGi2MgLufcANWAt3A9rx9NwD7gI5ouzTve98FdgE7gYsL/fvRa1ybtpCtvb3dQ7z++uteX1+fer8Z29pD/h7dPWjEsAqYc5z9t7p7a7Q9BGBmk4D5wLnRa24zM63nLSXR3NzMeeedF1S7du1a3RsxAgWDwd3/APQE/nuXAWvc/aC7v0hu5BC+GJ/ICdxyyy3BtXfffXeCnVS/kcwxfMvMtprZSjMbXD7nDKAzr6Yr2hdjZovNrN3M2kfQg9SQSy65JKiuu7ubtra2ZJupcsMNhp8D7wNagZeB8CiPuPsKd58WOksqte3mm29mzJgxQbUXXXRR8FLycnzDCgZ3f8XdD7n7YeCX/PtwYR+Qv2B/U7RPZNjq6uqCP2XqjTfeYOvWrQl3VP2GFQxmNj7v6eeA7dHj9cB8MxtlZhOAs4GnR9ai1LoLL7yQcePGBdU+8MADCXdTG04uVGBmvwFmAWPNrAu4HphlZq3kToHsAb4B4O7Pmtm9wA5gALja3XW/q4xIMZ9JuWTJkgQ7qR268lEyrb6+ngMHDlBfX1+w9oknnuCCCy4oQ1cVS1c+SnWYN29eUCiAPmGqlDRikEw7fPhw8EIrWpClII0YpDrojz0dCgapCvogmdJSMEhmTZkyJbj2rrvuSrCT2qNgkMwq5jSl7o0oLU0+SibV1dXx0ksvBV3Y9NxzzzFp0qQydFXxNPkolW3VqlVBoeDuzJo1K/mGaoyCQTKnvr6eL37xi0G1jz32mCYeE6BgkMwp5qImzS0kQ8EgmRM66djf38/atWsT7qY2KRgkU4r5aPv77rtPy7clRGclJFN27NjBOeecU7Cuu7ub9773vVqQpTg6KyGVZ8qUKUGhALkLmhQKyVEwSGbogqbs0KGEZEIxFzSBbq4aJh1KSGUpZvk2SZ6CQTKhmMOILIxyq52CQTLhyiuvDK5duHBhgp0IaI5BMiL097C/v5/GxkZdvzA8mmOQylHM3IIuaioPBYOkrphDAy3IUh46lJDU6WrHstGhhFQGXe2YTRoxSGq0SlPZacQg2VfMRU0rV65MuBvJp2CQ1IRe1OTumnQsMwWDpELLt2WbgkFSoeXbMs7dU98A11Y727hx4zzU3XffnXq/VbS1h/5NasQgZfeTn/wkuFZzC+nQ6Uopu56eHhobG4NqTzrpJF27UDo6XSnZ1NDQEBwKgEIhJQWDwcyazewJM9thZs+a2bej/aeZ2UYzeyH62hjtNzP7mZntMrOtZjY16f8IqRyzZ89OuwUJEDJiGACWuPskYAZwtZlNApYCj7v72cDj0XOAS4Czo20x8POSdy0Vq5hgePPNNxPsRE5oGGcQHgQuAnYC46N944Gd0eNfAFfk1R+p01kJbcWYMWNG6v1W2ZbMWQkzawE+BGwGTnf3l6Nv7QdOjx6fAXTmvawr2icSrLe3l82bN6fdRs06ObTQzMYA64Br3P21/FV63d2LPbNgZovJHWqIxGzcuFETjykKGjGY2SnkQuHX7n5/tPsVMxsffX88MHjN6j6gOe/lTdG+o7j7CnefFnr6RCrfqFGjgmsfeeSRBDuRQkLOShhwB/Ccuy/L+9Z6YGH0eCG5uYfB/V+Nzk7MAPryDjmkhs2aNSu4dsOGDck1IgWFHEp8FFgAbDOzjmjftcCNwL1m9jVgLzAv+t5DwKXALuBN4L9K2rFUrDlz5gTV7dixQzdNpUxXPkpZNDU10dnZWbiQXIDoUCIRuvJRsiV0tHDw4EHa2tqSbUYKUjBIWVx88cVBdW1tbRw8eDDhbqQQBYMkzsz45Cc/GVSrQ4hsUDBI4s4//3waGhqCahUM2aBgkMSFzi90dXWxY8eOhLuREDorIYlqaGigp6eH/CtlhzJv3jzWrl1bhq5qls5KSDbMnj07KBTcnY0bN5ahIwmhYJBEhZ6N2Lx5M729vQl3I6EUDJKoT3/600F1Dz/8cMKdSDEUDJKYc889N/iTpnQ2IlsUDJKYZcuWFS6KPPXUUwl2IsXSWQlJTH9/f/Ct1iETlDJiOish6Stm/QXJFgWDpE4XNWWPgkFSp4nH7FEwSCKampqCaxUM2aNgkETceuutQXWPPPKIgiGDFAxScrrNuvIpGKTkdJt15VMwSMnpNuvKp2CQkvvEJz4RVKfRQnYpGKTkmpubCxehYMgyBYOUXMjt021tbVqUJcMUDFJyK1euLFhz4403lqETGbbQj8VOciP9jwfXVsJt1KhR/uSTTw758fZ//vOfU++xRrf20L9JjRik5A4ePDjkAi3t7e184QtfKHNHUiwFgySip6eHL33pS/zxj38EcvMOjz/+OB/+8Id56aWXUu5OCtF6DCK1Q+sxiMjwKRhEJEbBICIxCgYRiVEwiEiMgkFEYgoGg5k1m9kTZrbDzJ41s29H+28ws31m1hFtl+a95rtmtsvMdppZ2GeUiUhmnBxQMwAscfe/mtk7gGfMbPDTR29195vzi81sEjAfOBf4D+AxM/tPdz9UysZFJDkFRwzu/rK7/zV6/DrwHHDGCV5yGbDG3Q+6+4vALmB6KZoVkfIoao7BzFqADwGbo13fMrOtZrbSzBqjfWcAnXkv6+I4QWJmi82s3czai+5aRBIVHAxmNgZYB1zj7q8BPwfeB7QCLwO3FPOD3X2Fu08LvURTRMonKBjM7BRyofBrd78fwN1fcfdD7n4Y+CX/PlzYB+Qv4dMU7RORChFyVsKAO4Dn3H1Z3v7xeWWfA7ZHj9cD881slJlNAM4Gni5dyyKStJCzEh8FFgDbzKwj2nctcIWZtZJbAGIP8A0Ad3/WzO4FdpA7o3G1zkiIVJas3Hb9KvB/wL/S7iXAWCqjT6icXtVn6R2v17Pc/T0hL85EMACYWXslTERWSp9QOb2qz9Ibaa+6JFpEYhQMIhKTpWBYkXYDgSqlT6icXtVn6Y2o18zMMYhIdmRpxCAiGZF6MJjZnOj27F1mtjTtfo5lZnvMbFt0a3l7tO80M9toZi9EXxsL/TsJ9LXSzLrNbHvevuP2ZTk/i97jrWY2NQO9Zu62/RMsMZCp97UsSyGk/AlUdcA/gInAqcAWYFLan4x1TI97gLHH7LsJWBo9Xgr8OIW+ZgJTge2F+gIuBX4PGDAD2JyBXm8A/vs4tZOi34NRwITo96OuTH2OB6ZGj98B/D3qJ1Pv6wn6LNl7mvaIYTqwy913u/tbwBpyt21n3WXAndHjO4G55W7A3f8A9Byze6i+LgPu8pyngIZjLmlP1BC9DiW12/Z96CUGMvW+nqDPoRT9nqYdDEG3aKfMgUfN7BkzWxztO93dX44e7wdOT6e1mKH6yur7POzb9pN2zBIDmX1fS7kUQr60g6ESfMzdpwKXAFeb2cz8b3purJa5UztZ7SvPiG7bT9Jxlhg4Ikvva6mXQsiXdjBk/hZtd98Xfe0GfkduCPbK4JAx+tqdXodHGaqvzL3PntHb9o+3xAAZfF+TXgoh7WD4C3C2mU0ws1PJrRW5PuWejjCz0dE6l5jZaGA2udvL1wMLo7KFwIPpdBgzVF/rga9Gs+gzgL68oXEqsnjb/lBLDJCx93WoPkv6npZjFrXADOul5GZV/wF8L+1+jultIrnZ3C3As4P9Ae8GHgdeAB4DTkuht9+QGy6+Te6Y8WtD9UVu1nx59B5vA6ZloNe7o162Rr+44/Pqvxf1uhO4pIx9fozcYcJWoCPaLs3a+3qCPkv2nurKRxGJSftQQkQySMEgIjEKBhGJUTCISIyCQURiFAwiEqNgEJEYBYOIxPw/cxj3aJP8qj0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_number_and_image(X_all, Y_all, 777)  # prints label and plots image with index number 777 in X_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quick sanity check, let's take a look at the information we processed and how its stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_all contains 1010 labels stored as one-hot-encoded np.arrays of 10 classes (digits 0 to 9).\n"
     ]
    }
   ],
   "source": [
    "print (\"Y_all contains {} labels stored as one-hot-encoded np.arrays of {} classes (digits 0 to 9).\".format(\n",
    "    *Y_all.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_all contains 1010 images with the ratio 256 x 256 and 1 channel.\n"
     ]
    }
   ],
   "source": [
    "print (\"X_all contains {} images with the ratio {} x {} and {} channel.\".format(*X_all.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After masking, we end up with following data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train - shape: (606, 256, 256, 1)\n",
      "Y_train - shape: (606, 10)\n",
      "X_dev - shape: (202, 256, 256, 1)\n",
      "Y_dev - shape: (202, 10)\n",
      "X_test - shape: (202, 256, 256, 1)\n",
      "Y_test - shape: (202, 10)\n"
     ]
    }
   ],
   "source": [
    "print (\"X_train - shape: {}\".format(X_train.shape))\n",
    "print (\"Y_train - shape: {}\".format(Y_train.shape))\n",
    "print (\"X_dev - shape: {}\".format(X_dev.shape))\n",
    "print (\"Y_dev - shape: {}\".format(Y_dev.shape))\n",
    "print (\"X_test - shape: {}\".format(X_test.shape))\n",
    "print (\"Y_test - shape: {}\".format(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "606 images for training and each 202 images for development and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow offers a standardized way to create your own [custom estimators](https://www.tensorflow.org/get_started/custom_estimators). These estimators can be adjusted to fit your needs and structure. For our first base model we decided to go for the following setup:\n",
    "\n",
    "* Two convolutional layers, of a kernel size 5 x 5 each. \n",
    "    * The first layer with 32 \n",
    "    * The second with 64 filters\n",
    "* Both apply same padding and are activated through a ReLu function\n",
    "* After each convolutional layer max pooling is performed with a window size of 2x2 and a stride of 2. \n",
    "* After the second pooling step the multidimensional tensor is being flattened and fed through a fully connected layer with 1024 neurons. \n",
    "* This layer feeds into a fully connected layer with 10 units which determines the probability of the image being a certain class through softmax. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit_cnn_base_fn(features, labels, mode):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Network model to recognize hand-written digits.\n",
    "    \"\"\"\n",
    "    \n",
    "    # input layer\n",
    "    # [batch_size, image_width, image_height, channels]\n",
    "    # -1 means batch_size is being automatically computed\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 256, 256, 1])\n",
    "    \n",
    "    # first convolution\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=32,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # pooling 1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    # second convolution\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # pooling 2\n",
    "    pool2 = tf.layers.max_pooling2d(\n",
    "        inputs=conv2, \n",
    "        pool_size=[2, 2], \n",
    "        strides=2)\n",
    "    \n",
    "    # flatten data\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 64 * 64 * 64])\n",
    "    \n",
    "    # first fully connected dense layer\n",
    "    dense = tf.layers.dense(\n",
    "        inputs=pool2_flat, \n",
    "        units=1024, \n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # second fully connected dense \"logits\" layer\n",
    "    logits = tf.layers.dense(inputs=dense, units=10)\n",
    "    \n",
    "    # if predicting and evaluating - generate predictions\n",
    "    predictions = {\n",
    "        \"class\": tf.argmax(logits, axis=1),\n",
    "        \"probabilities\": tf.nn.softmax(logits)\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    \n",
    "    # if training and evaluating - calculate loss\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    \n",
    "    # define training mode\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        \n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        eval_metrics_op = {\n",
    "            \"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"class\"])\n",
    "        }\n",
    "        \n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op, eval_metric_ops=eval_metrics_op)\n",
    "    \n",
    "    # define evaluation mode\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        eval_metrics_op = {\n",
    "            \"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"class\"])\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metrics_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the data is being processed and put into the right input format for this custom estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = X_train\n",
    "train_data = train_data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data has a shape of (606, 256, 256, 1) (number of images, width, height, channels)\n"
     ]
    }
   ],
   "source": [
    "print (\"The training data has a shape of {} (number of images, width, height, channels)\".format(train_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The evaluation labels have a shape of (606, 10) (number of labels, number of classes)\n"
     ]
    }
   ],
   "source": [
    "print (\"The evaluation labels have a shape of {} (number of labels, number of classes)\".format(Y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = Y_train\n",
    "eval_data = X_dev\n",
    "eval_labels = Y_dev\n",
    "eval_data = eval_data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we link the custom function with the TensorFlow Estimator class and retrieve everything. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'digit_base_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc26130df60>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "digit_base_classifier = tf.estimator.Estimator(\n",
    "    model_fn=digit_cnn_base_fn, model_dir=\"digit_base_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn into Distinct Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_encoding(labels):\n",
    "    y_nohe = np.zeros(shape=(labels.shape[0], 1), dtype=int)\n",
    "    for idx, el in enumerate(labels):  # reformat into non-one-hot-encodings\n",
    "        y_nohe[idx] = np.argmax(el)\n",
    "    return y_nohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(606, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_nohe = distinct_encoding(train_labels)\n",
    "y_train_nohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data},\n",
    "    y=y_train_nohe,\n",
    "    batch_size=32,\n",
    "    num_epochs=10,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into digit_base_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 14.315405, step = 1\n",
      "INFO:tensorflow:global_step/sec: 9.74701\n",
      "INFO:tensorflow:loss = 0.007737709, step = 101 (10.260 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 190 into digit_base_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0024613673.\n"
     ]
    }
   ],
   "source": [
    "training_results = digit_base_classifier.train(\n",
    "    input_fn=train_base_input_fn,\n",
    "    steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval_nohe = distinct_encoding(eval_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-07-24-22:45:38\n",
      "INFO:tensorflow:Restoring parameters from digit_base_model/model.ckpt-190\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-24-22:45:39\n",
      "INFO:tensorflow:Saving dict for global step 190: accuracy = 0.519802, global_step = 190, loss = 1.8483627\n",
      "{'accuracy': 0.519802, 'loss': 1.8483627, 'global_step': 190}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and print results\n",
    "eval_base_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data},\n",
    "    y=y_eval_nohe,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_results = digit_base_classifier.evaluate(input_fn=eval_base_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Wait, what? Roughly 52 % accuracy on the development set? That can't be right. After running a few more tests an in-depth look at the numbers shows one possible reason. The model has an incredible high variance. In fact, on the training set, it shows close to 0 loss. It seems like the model is overfitting. In order to work our way around this problem, we take the first route and try regularizing the model. Adding a dropout layer with a dropout probability of 60 % should help to regularize the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit_cnn_dropout_function(features, labels, mode):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Network model to recognize hand-written digits.\n",
    "    \"\"\"\n",
    "    \n",
    "    # input layer\n",
    "    # [batch_size, image_width, image_height, channels]\n",
    "    # -1 means batch_size is being automatically computed\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 256, 256, 1])\n",
    "    \n",
    "    # first convolution\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=32,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # pooling 1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    # second convolution\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # pooling 2\n",
    "    pool2 = tf.layers.max_pooling2d(\n",
    "        inputs=conv2, \n",
    "        pool_size=[2, 2], \n",
    "        strides=2)\n",
    "    \n",
    "    # flatten data\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 64 * 64 * 64])\n",
    "    \n",
    "    # first fully connected dense layer\n",
    "    dense = tf.layers.dense(\n",
    "        inputs=pool2_flat, \n",
    "        units=1024, \n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # dropout layer\n",
    "    dropout = tf.layers.dropout(\n",
    "        inputs=dense, \n",
    "        rate=.6, \n",
    "        training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    # second fully connected dense \"logits\" layer\n",
    "    logits = tf.layers.dense(inputs=dense, units=10)\n",
    "    \n",
    "    # if predicting and evaluating - generate predictions\n",
    "    predictions = {\n",
    "        \"class\": tf.argmax(logits, axis=1),\n",
    "        \"probabilities\": tf.nn.softmax(logits)\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    \n",
    "    # if training and evaluating - calculate loss\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    \n",
    "    # define training mode\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "    \n",
    "    # define evaluation mode\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        eval_metrics_op = {\n",
    "            \"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"class\"])\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metrics_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'digit_dropout_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc225265208>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "digit_dropout_classifier = tf.estimator.Estimator(\n",
    "    model_fn=digit_cnn_dropout_function, model_dir=\"digit_dropout_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dropout_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data},\n",
    "    y=y_train_nohe,\n",
    "    batch_size=32,\n",
    "    num_epochs=10,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into digit_dropout_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 16.82959, step = 1\n",
      "INFO:tensorflow:global_step/sec: 9.97865\n",
      "INFO:tensorflow:loss = 0.22032285, step = 101 (10.023 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 190 into digit_dropout_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.016385254.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7f5322a06e10>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_dropout_classifier.train(\n",
    "    input_fn=train_dropout_input_fn,\n",
    "    steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-07-24-22:46:52\n",
      "INFO:tensorflow:Restoring parameters from digit_dropout_model/model.ckpt-190\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-24-22:46:53\n",
      "INFO:tensorflow:Saving dict for global step 190: accuracy = 0.54950494, global_step = 190, loss = 1.7509946\n",
      "{'accuracy': 0.54950494, 'loss': 1.7509946, 'global_step': 190}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and print results\n",
    "eval_dropout_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data},\n",
    "    y=y_eval_nohe,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_results = digit_dropout_classifier.evaluate(input_fn=eval_dropout_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy up - loss down\n",
    "Well. Looks like we got rid of some of the variance. And we slightly increased the accuracy. For a supervised learning task with 10 classes scoring 54% is still better than random guessing (which would yield around 10% accuracy) but we should be able to do better. Even with 10 epochs, the model should be able to perform better. Since we got rid of the overfitting problem, and seem to have a solid baseline it's time to move on and investigate the data.\n",
    "\n",
    "As widely known, neural nets perform best if enough data is being funneled into them. A total dataset of 1010 images hardly counts as exhaustive. (Even though gathering those 1010 images took quite some painting time). Luckily there might be hope for us that might free us up some time that we can spend watching cute animals rather than drawing 10,000 more images. `Data augmentation` to the rescue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "By simply shifting and rotating the images we should be able to vary the images so much that these generated images could count as new data. Let's try it. To perform this efficiently and make it faster to train we'll resize the existing images as well. Generating `28x28` pixel images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zoom Shift\n",
    "First, to take into account smaller numbers as well as to make the model invariant to the drawing position we'll zoom out of the image and place the smaller digit in all four corners of the image. In combination with rotations this should give a broad variety of images to train on. (And also help with hiding my terrible hand-writing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom_out_and_shift(img, label):\n",
    "    zeros_img = []\n",
    "    labels = [label] * 4\n",
    "    for i in range(4):\n",
    "        zeros_img.append(np.copy(np.zeros_like(img)))\n",
    "    zoomed_img = scipy.ndimage.zoom(img[:,:,0], .65)\n",
    "    zeros_img[0][:zoomed_img.shape[0],:zoomed_img.shape[1],0] = zoomed_img  # top left\n",
    "    zeros_img[1][-zoomed_img.shape[0]:,:zoomed_img.shape[1],0] = zoomed_img  # bottom left\n",
    "    zeros_img[2][:zoomed_img.shape[0],-zoomed_img.shape[1]:,0] = zoomed_img  # top right\n",
    "    zeros_img[3][-zoomed_img.shape[0]:,-zoomed_img.shape[1]:,0] = zoomed_img  # bottom right\n",
    "    return zeros_img, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zoom out and shift image to four corners\n",
    "X_zoom, Y_zoom = [], []\n",
    "for ximg, ylabel in zip(X_train, Y_train):\n",
    "    X_zoom.append(ximg)\n",
    "    Y_zoom.append(ylabel)\n",
    "    xzoom_tmp, yzoom_tmp = zoom_out_and_shift(ximg, ylabel)\n",
    "    X_zoom.extend(xzoom_tmp)\n",
    "    Y_zoom.extend(yzoom_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After transformation for any of the 606 trainign examples 4 new images are added to the list. Those images look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_zoom_images(xzoom, orig):\n",
    "    plt_images = []\n",
    "    plt_images.append(orig)\n",
    "    plt_images.extend(xzoom)\n",
    "    title_list = ['original', 'top_left', 'bottom_left', 'top_right', 'bottom_right']\n",
    "    w=10\n",
    "    h=10\n",
    "    fig=plt.figure(figsize=(14, 4))\n",
    "    columns = 5\n",
    "    rows = 1\n",
    "    for i in range(1, columns*rows +1):\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(plt_images[i-1][:,:,0], cmap='gray')\n",
    "        plt.title(title_list[i-1])\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzkAAAC2CAYAAAD6HEOJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAIABJREFUeJzt3Xt8XFW99/Hvb+/J5NKkTUtrtUDpxYIVjy0IViGcpj5YhVJEBaygXFrF+oCPVI96jpwDKIg+B5U+PKj4skoRkFOEx6JyE7nYFuXEQikgFY7chCO9N2mSJpnM7PX8MZMxOzO5tEnmsvt5v17zenX2XnvPL+nK2vPba+21zDknAAAAAIgKr9gBAAAAAMBIIskBAAAAECkkOQAAAAAihSQHAAAAQKSQ5AAAAACIFJIcAAAAAJFCklNAZnajmf3bSJcd5DzTzMyZWWy458LBycwazez1IZY1M7vJzPaYWdNoxwYAhWRmJ5nZ80MsO+S2E6XBzF4xs5OLHcdIMrOvmtmqIZa90sxuHe2YCoUkp4Ccc8udc1eNdFkc3EqsUW6Q9H5Jhznn3s1FvjyVWJ3ab/tzoTazyWa2zsxazew7ox0bRk4x6qlzbr1z7qiROJeZrTazq0fiXCiuzM3kt/Z6XzLXPufcNc65T43Eucrt2kCSUyBm5hc7BqAAjpD0inOuvdiBoPBK+UI/gIsk7ZQ01jn3xajdycTIYUQEys3BXmdJcobJzGab2aNm1mxmfzKz0zPbV5vZD8zsXjNrl7Sg710bM/uymb1hZn8zs0/1/oLQu2zPFwUz+6KZbc8cc2Gv8ywys01mttfMXjOzKwv7W0CxmNktkqZK+pWZtWXq1OmZuticqZuze5V/xcz+xcyeywwpu8nMqvbzM6eY2V1mtsPMXjaz/5XZvkzSKknvzcRyraT7JE3JvG8zsykj99MDI+IISc8551yxA8HQFaLt63Xt/YqZbZV0U9/E3cyOzVx/W83s52a2pm/vTL5rt5ldJOlcSV/OxP+rEfz1YHiOz1dPzOzTZvYXM9ttZr/suZ6Z2brMcZsz/5fnK8+1z8wqzWxl5jvf3zL/rsyco6eufblXXTnDzE41sxcyn/nVwQLP3KS508xuNbO9ki7oe+PGzM4zs1fNbJeZ/Zvl9s7EzeynmTr9JzM7LnNczt/cCPyuR5dzjtcBviRVSPqLpK9Kikt6n6RWSUdJWi2pRdKJSieTVZltV2eO/aCkrZKOllQj6VZJTtJbM/t7l22UlJT09cxnnippn6Txvfb/Q+Zz3ilpm6QzMvumZc4bK/bvi9eo1cNXJJ2c+feRktqVHjJWIenLmToa71X2WUmHS5og6bGeejbA+RslvZ75tyfpCUmXZ+r8DEkvSfpAZv8FkjbkO5ZX+bwy9eRfJD0naY+kmyRVZfZ9OlOndkv6paQpme3rMm1Nu6Q2SedL6pAUZN63SZoiqVLSSkl/y7xWSqrsXV8y9Xa7pDcknZFp817IfOZXhxD/lZJu7fX+PZJ+L6lZ0mZJjZntqyV1S0pk4jst8+/uzPvNxf6/4DVoPR3tti8p6X9n6m11n/YwLulVSZ/PfOZHMvVnqNfu1YPFwKsodSqnnij9/W6npGMzdeH/SlrX67js97de//ev9zn31yU9LulNkiZl2qSr+tSVyzN15dOSdkj6maQ6pb8rdkiaPkj8V2barzOUvl5X924PJb0907Y1ZOrvtzPlT+51fGemrvqSvinp8T6/n5OL/f801Bc9OcPzHkm1kr7lnEs45x6W9GtJH8/sv9s595hzLnDOdfY59mxJNznn/uSc26d0xRpIt6SvO+e6nXP3Kl1Jj5Ik59yjzrlnMp/ztKTbJc0fkZ8Q5eZjku5xzj3onOtWugGrlnRCrzI3OOdec87tlvQN/b2+DsXxkiY5576eqfMvSfqRpCUjFD9Kx7mSPiBpptJfIP/VzN6n9EXvbElvUfoL3n9IknPuHzPHzXHO1TrnbpZ0iqS/Zd7XOuf+JukypdvOuZLmSHq3pH/t9blvVvqm0KFKX/B/JOkTkt4l6SRJ/2Zm04f6Q5jZoZLuUfqLygRJ/yTpLjOb5Jy7QNJtkv49E9+vJV0jaU3m/Zwh/7ZQbKPV9gWSrnDOdTnnOvrse4+kmKTrM9fm/yep74Qr/V67UbLy1ZNzJf3EOfekc65L6ZtA7zWzaftx3nOVrgvbnXM7JH1N0id77e+W9I1M/f0PSRMl/R/nXKtz7k9K33QaSpv0B+fc2sx3wr519kxJv3LObXDOJZRuY/v2Ym9wzt3rnEtJumWIn1mSSHKGZ4qk15xzQa9tryp9cZak1wY7ttf7gcpK0i7nXLLX+31KJ1gys3lm9khm+FCLpOVK/3Hg4DNF6TooScrUzdf09zophevaq5ljhuoIpbvgm3teSvdkTj7wkFGiyv1C3+MTku7NXLQD59yDkjYqfacS0TFabd+OPDcpe3/mf7vMLe48nyENcO1GycpXT/rWrzZJuxSuX4MJnUO5dXBXJrGQ0r02UnpkjnptG0rdGfJ3z8xN9l19ymzt9e99kqqsTJ/tIckZnr9JOtzMev8ep0r678y/Bxrj/Yakw3q9P3wYcfxM6WEjhzvnxkm6UZIN43woL73r2d+UTkQkpad0Vrpu/XevMr3r2tTMMUP1mqSXnXP1vV51zrn+vjDynEP5KvcLfY8jJJ3VJzFvULonCuWtEG3fYNfxQzOfle8zhnNuFE++etK3fo2RdIjC9au3fP+3oXNo/6+/QzXk755mVq30zzES5y45JDnD859KZ7lfNrMKM2uUtFiZ4RuDuEPShZaeuKBG0nDWxKmTtNs512lm75Z0zjDOhfKzTelnY6R0vVpkZv/DzCokfVFSl9Jjf3tcbGaHmdkEpYcOrdmPz2qS1Jp5ELfazHwze4eZHT9AbIeY2bj9+olQCsr9Qt/jNUm39EnMxzjnvtVP+bK6iB/kCtn25fMHSSlJl5hZzMw+pPTwywOJH6UjXz25XenvbHMzkwVcI+k/nXOvZI7p+3+Z79p3u9LDfieZ2USlh4oVeibHOyUtNrMTzCyu9KMS+3NTvKzqLEnOMGTGMy5Wetz5Tknfl3Sec+7PQzj2PknXS3pE6YcjH8/s6jqAUP6npK+bWavSfzR3HMA5UL6+qXTD2ax0ffyE0g9F7sy8X5ypqz1+Juk3Sk8Y8KLSzyoMSeYO+2lKP0/xcuYzVknKm8Rk/hZul/RS5i46s6uVj6hc6G9V+qL+gUxSXpWZyeiwfspvkzStTw89SlPB2r58Muf+iKRlSk9q8Qmln8sd6nX8x5Lenmkb1w4nFoyonHrinPut0jej71K6N2Smws+iXinp5sz/5dn9XPuuVnqo7NOSnpH0pIZZB/dXZsjv55S+Gf+G0s+IbdfQ62z2b87M/ml0ohw5Fh5KimKx9FSXzyo9y1BysPLAgTCzVyR9KtNgA3ll6skPlX5WZoqkuyV91jm3z8yWS/qSpPFK3yVf7px7PXPccklXKP3A90XOuTvM7CeSPqT0TD1vV3qGtH+XdFbm434u6cuZnuhGpWcBOixzvpjSz+hM70mkzGyDpBudc/0mRpaeRv+tzrlPZN7Py3zmPyh9570p8/P81cxWKz0L0r9myh6S+XmPVnpo5rEH+GtECSlU22dm/6l0/bxpND8HGAlmVqt0gj7LOfdyseMZaSQ5RWRmH5Z0r9JTSN8sKXDOnVHcqBBlJDkADkaj1faZ2XxJzyvde3Su0s/EznDOvTGSnwOMFDNbLOkhpYepfUfSPEnHuggmBHTHF9dnlO4mfFHpu4ufLW44OFiZ2Vft74uW9X7dV+zYAGC0jEDbd5TSay81K/0c0JkkOBhNZnZfP3V20MVCMz6kvz9jOUvSkigmOBI9OQCAMpT5EnpSnl3XOOeuKXQ8AIDSQpIDAAAAIFIYrgYAAAAgUkpiBVMzozsJeTnnCrao6ezZs6mHyGvLli0FqYfUQfSnUHVQoh6if9RDlIKh1kN6cgAAAABECkkOAAAAgEghyQEAAAAQKSQ5AAAAACKFJAcAAABApJDkAAAAAIgUkhwAAAAAkUKSAwAAACBSSHIAAAAARApJDgAAAIBIIckBAAAAECkkOQAAAAAihSQHAAAAQKSQ5AAAAACIFJIcoIx4Xv4/2f62AwBKD202MPpixQ4AwNB4nqfOzk7NmjVLH/jAB/ShD30ou6+xsVHjxo1TMpksYoQAgMH4vq/29nYtWrRI5513niZOnChJevHFF/WFL3xBQRAoCIIiRwmUP5IcoMR5nqexY8fqnnvuUSqVylvmySef1AsvvKCLLrqo3zIAgOKpr6/XZZddpnnz5uXdP3fuXP3whz/Uueeeq5qaGhIdYJhIcoASds455+iiiy6S53kDJi/OOc2aNUsPPfSQ5s+fLzMrYJQAgP74vq/HH39cHR0dg5adNWuWHn/8cb344otatmxZAaIDootBoUCJOuaYY/T5z39evu8P+Rjf97V06VLGewNAkXmepyAItGrVKrW3tw/5ON/3dfTRR9OTAwwT34SAEuP7vm644QZdd9116urqknMuu8/MlEwmVVlZqfHjxysej4eOdc5pxYoVhQ4ZAJDRc5PJzLRx40bNnDmz3xtPtbW1mjRpUmibc04dHR3as2cPN6yAYWC4GlAifN/X9OnTtXr16rx38JLJpH784x/r5ptvlud58jxPjz32WBEiBQDk0zNBzNq1azV58mR1dnaG9puZxowZo4ULF2rr1q2KxWK64IILtGzZstANLQDDR5IDlADf97VhwwYlEomcBCeZTKqjo0OLFi2SJMViMcXjcT3yyCNMMgAAJcLzPLW2tuqJJ57I2Wdm2rt3rz772c/q9ddfVxAEisVimj17tpYuXUqCA4wCkhygBHz0ox9VMpnMmTCgurpaxx9/fGhbT0LU9w4hAKB4UqmUnn32WXV1dYW2O+d08cUX65lnngltP+aYY3T99deT4ACjhCQHKLKqqipdcsklORe6pUuX6qWXXgpt831fq1atIsEBgBISi8X0wAMP5CQ4ra2tOuWUU3KerfF9X9dddx0JDjCKSHJKxPz589XY2KglS5Zo2rRpqqqqyu5rbm7W+PHjixgdRkPPzDsPPPBAaHtlZWW/6ygcd9xxmjFjRiHCAwAM0Y4dO3ISmc985jPasmVL3skD1q9fH1q82cxIeIARRpJTRLfddpvOOeecQcvV19fLOcfaJxFVU1OTXT8hmUxqzpw5oaQ2CAL5vq/TTjtNl156aagetLa2qq6uruAxAwD+LgiCUJJSXV0dSnB62vGOjg49++yzamtry5Z1zunoo4/WU089pYqKioLHDkQVSU4RdHR0hHpqhqq5uVn19fWjEBFKhZmpoaFBf/jDH7ITEJxwwgm67LLLdNhhh4Uuop7nadGiRVq3bl2xwgUA5JFKpTRmzBi98cYbktI3s26//XZNmTIllOBI0o033shNTGAUkOQUSH19va644gpdeumlB3yOcePGyTmnlpYWzZkzR6+++uoIRohS4Pu+vv/97yuRSGS39dzZ653gpFIpLVy4sODxAQAGl0gk9Otf/zo0W2bfXpqeIWp33XVX3iSH4WvA8JDkFMimTZs0bdq0ETnXuHHjtHnzZnp1Iso5N+iQhd27d4cSob7HAwCKy/d9+b7f737nnBoaGhSL5f8qVlNTM1qhAQcFltIdZQ0NDXLOjViC02PcuHEjej4UXs8dvoaGhiEPVTAzXXzxxfroRz+aPf7pp58OlUkmk3kXEwUAjI4pU6aotrZ2yDeZuru79b73vS/7zE48Hlc8Hs/uNzMdfvjhtOXAMJDkjKJ169Zp/fr1xQ4DJa6rq0vvete79MADD6iyslLOOQVBEHp5nifnnE466aSctRY2bdoUet/d3V3I8AHgoNfV1aUTTjhBixcvVldXlyoqKvK245WVlXrppZe0cOHC7OxqQRDkTXJmzpxZrB8HiASGq42CxsZGPfLII0Mu/7vf/U6NjY052xl2dPCora3VN77xDV177bXasWOHUqlUdp+Zqbq6WmPHjs1OO93bH//4R11wwQXZ+tLd3c1sfABQYMlkUnv37tUHP/hBpVIp7d69O7S/pqZGtbW1oamje1RUVCgej2fX2TEzzZo1S01NTQWJHYgikpwRlkgkhjwF5Lp16zR//vy8+7gbf3DpSVwSiUS/ayL19wxO3wkoEokESQ4AFEnPTaqJEyfm7MuX4EjpxUR7P5tjZjryyCNHJ0DgIEGSM0Lq6+u1Z8+eIZcfP368mpub855n8+bN/T6IiOjbnzHYnueppaUl1Ovn+77i8Xi/F1MAwOjb37a8s7Mz+945p6lTp8r3/VDPPoCh45mcETLUBGfDhg0ys7wJzhFHHKE9e/Zo6tSpIx0eIqrnIhoEQbbnxvd9kmQAKCOJREK/+tWvQj3wc+bMoS0HhoEkZ5gaGhqGNLSsra1NJ510kk466aS8++vr6/XKK6+McHSICs/zsrPw5BOLxbIJj3NOy5cvL1RoAIAhGKwdf/jhh0O9P11dXWppaSlEaEAkkeQM0/r16we90zJ+/HjV1dVpw4YN/ZbZn6FuOLjEYjF1dnZqz549/a65UFlZGRrS8PGPf7xQ4QEAhqCzs1O7d+9WMpnMSXY8z9PDDz8casd7hq8NlBgB6B9/OcPws5/9bMD9X/jCF/odmtbbo48+OoJRIUpisZjuu+8+NTU16amnntKtt96aN6m+4447VF1dnX3f3yQFAIDCmzx5spqamrR582Y1NTVp3759oeSlZ5rp3u247/s688wzWSsHOEAkOcOwcOHCAfdfd911QzpPfzOs4eDmeZ727dun6urq7GxpM2bMUEdHR07Z5557LpT88KAqAJQGz/O0YsWKbDueSqW0bNmynOSlsrJSsVgs+1yOmemwww4rRshAJJDkDMMhhxzS776hTt872AxY/U0njINDW1ubkslkdva0trY2dXR05AxfWL9+fb9D2QAAxWNmWrx4cbYdd87pnHPOySlXWVmZ047X19cXJEYgikhyiqS+vl7OuQG/mK5YsWLQoW6AlE6WqSsAUL6CIFBzc3NoSYDa2toiRgSUN5KcIrj00ksHnWigpaVFK1euLFBEKHfJZFLbt2/PvmchUAAoL845bd++PTRT5uGHH04vPXCAmIB9lPS+E3Mg6KLG/kilUmpubtahhx6aHfcNACgfzjk1Nzdr8uTJ2W2TJ0+mPQcOED05Jaazs1PTpk0rdhgoM845ZuABgDLXtx2vq6srUiRA+SPJGYa2trYRPd+KFStUXV2tV199dUjlGxsbR/TzUb6SyaR27NiRfW9mobuBAIDSFgSBduzYERoJQpIDHDiSnGEYycZn/PjxPIODA+Z5nu69997QWO5FixYVOSoAwP649957VVNTk33f0dGRd9kAAIMjyRkmM9OPf/zjAz4+CIIhLRiaDz05B6d4PJ4zpMHzPD322GOh7UuXLi10aACAIei7DEDPtscee0xVVVXZbW1tbWpvb89bHsDA+KsZAZ/61Ke0YMGCAzqWhUAxkL4PnPq+r+nTp+ct29raGroQsiAoAJSGvmvixePxvLOmtba25gw9njhxIs9cAgeAJGeEPProozIzmZk+/OEPD/i8zoMPPqjx48fLzLRhw4YD/sy5c+ce8LEofUEQaNKkSaqurs4mO77v6/TTT89bvra2VvF4PPvezJh6FACKLJVK6dJLLw3dtKqqqsq5ERUEgWpra3XPPfdky8ZiMZ1wwgkFjReICpKcUbB27VrV1dVlk56+r4ULF47Iwo1MMx19QRBo27Zt2buAzjldcsklisViOeXGjBkTSnIk1ssBgFLQ1NQU6s1JJpNKJBI5w9DGjBmju+++O/vezDRlypSCxQlECUlOGWOoW/QFQaA1a9aExmhv3749b08hCQ0AlKaWlpZQO25mWrNmTc4wNDPL6eEZ7rp7wMGKJAcoYZ7n6cYbbwxdHOPxuK699loeRAWAMlFVVaWqqqpQwjJjxgwlEokiRgVEG9+SysCzzz5b7BBQJEEQqL6+XqeeempoeuiGhoacB1kBAKUpmUzq1FNPDbXbqVRKN954YxGjAqKNJKcMfO5znyt2CCgi55x27NihysrK7Dbf9/XHP/5Rzjn5vq9YLKZdu3apvb29iJECAPqzY8eOnJlY3/nOdyoWi8nzvGw7/p3vfCfU48M6OcCBiQ1eBMX26KOP9ruvsbFxwP0of0EQKAgCLV68WD//+c+zM6Z1dXWpqalJtbW1ktJD23pPPQoAKB3JZFKxWExmlk1iPM/Tb3/7W02YMEG+78vzPG3bti10XEVFRTHCBcoePTll7owzzih2CCiQvXv3qru7OzTBQFdXl3bt2qVdu3aR4ABAGTj22GNDEw54nqfm5uZsO973ecu+s2kCGBqSnDJ3/vnnFzsEFEgikdBpp52mrVu3DjqTmpmpurqaBeQAoIQEQaC6ujo1NDSou7t70PKdnZ267777ChAZED0kOWWOtXIOLslkUqeddlrOFKN9Oed0+umnk+QAQIkJgkDxeFxjx44dtGx9fT3PWgIHiCSnwOrr6+Wcy74eeeSRIR33u9/9bpQjQznoWfRz/vz5+uQnP6lt27aptbU1+/rTn/6khoYGLViwQG+88UaxwwUA5BEEgebNm6fjjjtOP/nJT9TW1hZqyy+//HK95z3v0bx58wa9qQUgPyuFRabMrPhBFEi+3/eFF16o1atXD3jcBRdcoJtuuinvvigvAumcK9gPN3v27EjUQ8/z6MEZYVu2bClIPYxKHcTIK1QdlKiHhTRQe12KbTn1EKVgqPWQnpwS8L3vfW/QMoMlQUCPUrsoAgDyG6i9pi0HhockpwTU1NQM6/jGxsaRCQQA9oPnedkXAKA89W7Lo9SeMy8hAGDIYrGYksmkEomEOjs7s9snTJgQWs0dAFCaeoZCxmIxJRIJtbW1ZXsOY7HYsG++lwqSnAiYO3cuC4ICGDW+78vMNG7cON19992qq6vTvn37tG/fvmyZ2tpanXLKKdq9e3cRIwUADCQWi2nv3r1avny5/vmf/1nt7e2hJMf3fX3kIx9Rc3OzpPIeNhmdPqmDGNNIAxgt3d3duummm7Rp0ybdeeedCoJALS0t6u7uVkVFRfbV2dmp+++/X6effnqkhjsAQBT4vq+jjjpKmzZt0pNPPqlPf/rT2rlzpzo6OuT7frYt9zxP999/v5YtW6adO3eWdXtevpEja9q0acUOAUAEHXPMMXryySc1ffp07dmzR77v91vWzNTZ2akvfelLOv/888v6wggAUdEzNG3VqlX64Q9/qD179igIgryz/fbo7OzUeeedpxdeeKGshyFzFYoAkhwAI8n3fd1www267rrr1NXVFboYmpmSyaQqKys1fvx4xePx0LHOOa1YsaLQIQMAeum50WRm2rhxo2bOnNnvzafa2lpNmjQptM05p46ODu3Zs6dsb1qVZ9QIGejuKgDsr3/8x3/U29/+9pwLm5kpHo/r+eef12WXXaajjz5aTz75ZJGiBAD0x8zk+742btyorq6unP1BEKi7u1tr167VGWecoXHjxg3Yu1OOmHggAhoaGoodAoAIiMfjampqUmtra07vTRAEeuihh3TFFVfI8zw557R48WK94x3vKGLEAIC+YrGYvve972nWrFlqbW0N7XPOqbKyUvPmzVNFRYWSyaSSyaS2b9+uvXv3Fini0UGSAwBQEAS65557ci5yqVRK69ev1+WXXy7p70MgjjvuOH3lK18peJwAgP55nqfvf//7mj17ds7NqqqqKh1//PGKxWLyfT/7vE1TU1PkEhyJJKesvPjii5o5c2axwwAQMUEQaNOmTWpvb89uMzONHTtWCxcu1LZt27IPr0rSkUceqW9/+9vFChcA0I/3v//9OvLII0MJTjKZ1GuvvZadFKb3ZALPPPOM9uzZU4xQRx3P5JSRG264odghAIigCy+8MJTgJJNJffe739WcOXO0bds2SelEyPM8dXR06JZbbuFZQAAoMclkUldddVXoecra2lotWLBAS5culRRe9+Zzn/tcZBMciSSnrKxdu7bYIQCIkJ4L4SWXXJLdZmZau3atfvGLX+SUTaVSeuKJJ0IPsXZ3dxcmWADAgFpaWtTW1pZ975zTscceKzNTKpWS9Pd2f/r06TrrrLOyZT3P0wMPPBCpNp0kp4y88sor/e5rbGwsWBwAoqu7u1tXXXVVaFssFlNnZ6fWr18fugtoZjr77LMLHSIAYAhqampyZsns7OzU9ddfr9WrV4e2O+ci95wlz+SUiPr6ejU3Nx/w8Y2NjXr00UdHLiAAB6VYLKZnnnlGLS0t2W11dXUys5zpRd944w3t2rWr0CECAIago6ND999/f7Z3xvM81dbW5p0q+phjjsn29kQFPTkFtnnz5rzbr7zyymGd94tf/OKwjgeAHkEQqK6uLvuSlHNR3LFjh5YsWZL3+KittQAA5aqqqirblo8ZMyZv+9zQ0KCxY8fmPb66unq0Qxw1JDkF1l9vy/z584d13tra2mEdD+Dg9fLLL+9X+fr6ei1atCg7dO35558P7U8kEqFhbQCA0VdRUbFfk8IEQaAf/ehHqqqqUhAEqqioUEVFRXa/mWnq1Kll256T5BRYfz02c+fOLWwgAA56PReuJUuWaNu2bTIzmVm/5c1Mf/3rX/WOd7xDNTU12e1btmwJlYvakAcAKAdjx47Veeedp/HjxysIgn7bczNTd3e3Pv7xj+uWW25RIpGQlB6u3DfJOfzwwwsS+2jgmZwCG+i5m+E+lwMAByIIAi1ZskTt7e1673vfq+9+97t605velN2fTCb1yCOP6Ac/+IH+8pe/hNbMkZSdZroHSQ4AFMerr76qOXPmaMKECTr11FNzJhN48MEHdeedd+o3v/lN6GaVJPm+nzNRwZQpU7Rp06ZRj3s0kOSUkJdfflnjx48vdhgADkKpVEpVVVXatGmTTj755Jz9zrl+hyz8+c9/Dr1PJpNyzg3YKwQAGB1BEGjnzp269dZbddttt4X29bTlfRMcSdnhaj3LBJiZDj300ILEPBoYrlYEt99+e97t9fX1qq+vL3A0ABCWSqVyXv1xv+s1AAAIDElEQVQlOJ7n6YknngglNAMNkwAAFEYQBENuyyUpHo8rHo9n35uZ3va2txUi1FFBklME55xzTr/7Xn75ZRIdAGWj54LZ+8Lp+37eu4QAgNKVSqW0cePG7HvnnObMmaNYrDwHfpHkFMnXvva1vNvr6+u1c+fO/T4fU7YCKKbew9PMTPPmzStyRACA/ZFKpdTU1BTqiR87dqySyWQRozpwJDlFMtC6OL7v7/dDXiwECmA0eZ434NSk8Xg8O+GAc07Lli0rVGgAgCHqacv7TjDQ47777gtNHtPR0aG9e/f2W76UlV/EEdJfb46UnlLaOZfz6s+cOXNGI0QA0OTJk3XNNdfo4YcfVmVlZd4yPVNQ93jrW99aqPAAAEN0zTXX6Pe//70uvvjinBtXnufpqaeeynnGcsaMGWW5Vg5JThEN1JuzvyZMmDBi5wIAKX3BSyQSuuuuu3TiiSfKzLRu3Tp1d3fnlF21alXoOZzOzs5ChgoAGIDnefrWt76lE088UV1dXTr77LO1ZMmSUJkgCDR27FjV1NRkEx3f93XmmWcWI+RhI8kpspaWlmKHAAD9am9vVyqVyvYkt7e3q7OzM2fowmOPPRaalQcAUDrMTAsXLsy25c45nXHGGTnlqqqqctrygYYqlzKSnCKrr6/Xa6+9NuzzkCwBGA19h8r2N3Q2kUgc0KQpAIDC6DvcON8smKlUSjt37gy184ceeijP5ODATJ06ddiJDtNOAyimIAjU3t6efc86OQBQntrb20M9PpMmTSrLNp0kp0RMnTpVbW1tB3RsOVY8ANESBIE6OjqKHQYAYBicc+ro6Aj15PQ34UypI8kpIXV1dTIzmZlWrFiRN+lpa2vTihUrtGDBgmxZACi2ZDKpnTt3htbKAQCUF+dcznC1N7/5zWXZppfnEqYHgZUrV2rlypXFDgMAhiSZTGrbtm3Z9z0XRM/zynLqUQA4GAVBoG3btmn27NnZbTyTAwA4qHV1dWX/7ZzTySefTIIDAGWmq6sr1HOzb9++slwWgCQHADBsnudpzZo1oZWyzzrrrCJGBAA4EGvWrFFtbW32fUdHh/bt21d2vTnlFS0AoKD6jsP2fV9HHXVUTg+N53natGlTqPzb3va2gsQIABhcMpkMva+qqspZA6enLW9ubg4dV19fX3Y98yQ5AIB+VVZWhi6CnufpiCOOyFu2oqIidKfPzMruzh8ARJFzThs3bgxti8fjeScUqKio0Ouvv55973mepkyZMuoxjjSuPgCAvIIg0NixY0ND0CRp+fLlOXf/giBQbW1tzlSjJDkAUHxBEOjqq6/O2d7W1hZqp3va8ltvvTWbAPm+r3e/+90Fi3WkcPUBAPQrmUzqpZdeCg1zmD17trq7u3PK9u31AQCUji1btoTacuecPvzhD+cMQ6usrNR//dd/hbaVY9tOkgMAGNCXvvQlTZw4Mfu+q6tLM2bMKGJEAID9VVNTo4kTJ4bWwPnKV76iWCyaK8qQ5AAABrRr1y7dfPPNobHbv/jFL4oYEQDgQNx8882hpMbMNHny5CJGNHpIcgAAg7r66qtDSU5bW5ve8pa3SEo/d+N5nrq7u8tu9h0AOFj0PJdz7733ZreZme644w5VVVVJUrYtnzlzZrHCHDEkOQCAQVVXV+u2227LJjrOOd1+++1asGCBdu7cqV27dum5555TW1tb6LjewyIAAMVVXV2tb37zm6FtqVRKd911l3zf186dO/Xcc89p5cqV2fbbOReaba1ckOQAAAbleZ6uvfbaUE+N53m68sor9fTTT2vz5s3aunVrzsOp+aYnBQAUh+d5CoJAf/7zn0Pb6+rq9NBDD+npp5/W1q1b1dLSkt1nZjrssMMKHeqwkeQAAAbVM63oSSedFEp0etbC6XkBAEpXT/u9fPnynFkyB2rLE4lEQeIbSVyRAABDFovFNG/evCE9e/Oxj30sZ4VtAEDxBUGg97///aqurh60bFVVlX75y18WIKqRRZIDABiyIAg0btw4PfPMMxo3bpySyaS6u7uzL+ecDjnkEP30pz/V9u3bix0uAKAfQRDoxBNP1IQJExSPx0NteXd3t6qrqxWPx3XKKafkLApdDqI5MTYAYNQkEgl9/vOfVxAEam1tDU0u4Pt+NvkBAJS2RCKhuXPnqqOjQx0dHaF9tbW1isfjZduek+QAAPZbz3C1cePG5ewr1wsiAByMksmkKioqVFlZGdoeBEFZt+ckOQCAA8a6OAAQDVFrz3kmBwAAAECkkOQAAAAAiBSSHAAAAACRQpIDAAAAIFJIcgAAAABECkkOAAAAgEghyQEAAAAQKSQ5AAAAACKFJAcAAABApJDkAAAAAIgUkhwAAAAAkUKSAwAAACBSSHIAAAAARApJDgAAAIBIIckBAAAAECkkOQAAAAAihSQHAAAAQKSQ5AAAAACIFJIcAAAAAJFCkgMAAAAgUkhyAAAAAEQKSQ4AAACASCHJAQAAABApJDkAAAAAIoUkBwAAAECkmHOu2DEAAAAAwIihJwcAAABApJDkAAAAAIgUkhwAAAAAkUKSAwAAACBSSHIAAAAARApJDgAAAIBIIckBAAAAECkkOQAAAAAihSQHAAAAQKSQ5AAAAACIFJIcAAAAAJFCkgMAAAAgUkhyAAAAAEQKSQ4AAACASCHJAQAAABApJDkAAAAAIoUkBwAAAECkkOQAAAAAiBSSHAAAAACRQpIDAAAAIFJIcgAAAABECkkOAAAAgEghyQEAAAAQKf8f10Hw46iXKhIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1008x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_zoom_images(xzoom_tmp, ximg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After zoom augmentation there are 3,030 images in the dataset.\n"
     ]
    }
   ],
   "source": [
    "print ('After zoom augmentation there are {:,} images in the dataset.'.format(len(X_zoom)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize and Rotate\n",
    "Afterwards we'll resize and rotate those images to add even more images to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(X_aug):\n",
    "    X_new_aug = []\n",
    "    for X_tmp in X_aug:\n",
    "        X_new_aug.append(sktransform.resize(X_tmp, (28, 28)))\n",
    "    return np.array(X_new_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rvbin/.virtualenvs/digits_classifier/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/rvbin/.virtualenvs/digits_classifier/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "X_train_resized = resize(X_zoom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3030, 28, 28, 1)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_images(X_train, Y_train):\n",
    "    aug_list = []\n",
    "    aug_y_list = []\n",
    "    for ix, XY in enumerate(zip(X_train, Y_train)):\n",
    "        X_tmp, Y_tmp = XY[0], XY[1]\n",
    "        tmp_label = np.argmax(Y_tmp)\n",
    "        if ix % 10 == 0:\n",
    "            clear_output(True)\n",
    "            print ('{} / {}'.format(ix, len(X_train)))\n",
    "        \n",
    "        for rot_num in range(1, 21, 2):\n",
    "            rot_img = scipy.ndimage.interpolation.rotate(X_tmp, rot_num, reshape=False)\n",
    "            aug_list.append(rot_img)\n",
    "            aug_y_list.append(tmp_label)\n",
    "        for rot_num in range(-20, 0, 2):\n",
    "            rot_img = scipy.ndimage.interpolation.rotate(X_tmp, rot_num, reshape=False)\n",
    "            aug_list.append(rot_img)\n",
    "            aug_y_list.append(tmp_label)\n",
    "            \n",
    "    \n",
    "    return np.array(aug_list), np.array(aug_y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3020 / 3030\n"
     ]
    }
   ],
   "source": [
    "X_train_aug, y_train_aug = augment_images(X_train_resized, Y_zoom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After augmentation and resizing we have 60,600 images with shape 28 x 28 x 1\n"
     ]
    }
   ],
   "source": [
    "print ('After augmentation and resizing we have {:,} images with shape {} x {} x {}'.format(*X_train_aug.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those images look similar to this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_number_and_image(X_train_aug, y_train_aug, 23484)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev Set Pre-Processing\n",
    "Now we have to do the same pre-processing to the development set. We won't augment the data set since we'll take it as an estimation on how well the model performs on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202, 256, 256, 1)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rvbin/.virtualenvs/digits_classifier/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/rvbin/.virtualenvs/digits_classifier/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "X_dev_resized = resize(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202, 28, 28, 1)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev_resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev_resized = X_dev_resized.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_aug = X_train_aug.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Dropout\n",
    "Below is a sketch of the model. To help the model generalize better to new data, a dropout step between the first dense and the final layer is introduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CNN Structure](nb_img/cnn_structure.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit_cnn_aug_dropout_function(features, labels, mode):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Network model to recognize hand-written digits.\n",
    "    \"\"\"\n",
    "    \n",
    "    # input layer\n",
    "    # [batch_size, image_width, image_height, channels]\n",
    "    # -1 means batch_size is being automatically computed\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "    \n",
    "    # first convolution\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=32,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # pooling 1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    # second convolution\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # pooling 2\n",
    "    pool2 = tf.layers.max_pooling2d(\n",
    "        inputs=conv2, \n",
    "        pool_size=[2, 2], \n",
    "        strides=2)\n",
    "    \n",
    "    # flatten data\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "    \n",
    "    # first fully connected dense layer\n",
    "    dense = tf.layers.dense(\n",
    "        inputs=pool2_flat, \n",
    "        units=1024, \n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # dropout layer\n",
    "    dropout = tf.layers.dropout(\n",
    "        inputs=dense, \n",
    "        rate=.4, \n",
    "        training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    # second fully connected dense \"logits\" layer\n",
    "    logits = tf.layers.dense(inputs=dense, units=10)\n",
    "    \n",
    "    # if predicting and evaluating - generate predictions\n",
    "    predictions = {\n",
    "        \"class\": tf.argmax(logits, axis=1),\n",
    "        \"probabilities\": tf.nn.softmax(logits)\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    \n",
    "    # if training and evaluating - calculate loss\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    \n",
    "    # define training mode\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "    \n",
    "    # define evaluation mode\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        eval_metrics_op = {\n",
    "            \"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"class\"])\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metrics_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'digit_final', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc2245c7278>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "digit_aug_dropout_classifier = tf.estimator.Estimator(\n",
    "    model_fn=digit_cnn_aug_dropout_function, model_dir=\"digit_final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition the data is normalized to help the model converge quicker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_aug_norm = X_train_aug / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_aug_norm[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev_real = []\n",
    "for a in Y_dev:\n",
    "    y_dev_real.append(np.argmax(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 9\n"
     ]
    }
   ],
   "source": [
    "_ = print_number_and_image(X_train_aug_norm, y_train_aug, 244)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making sure the stratification has worked properly and all numbers are equally represented in the evaluation data set,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 20, 1: 20, 2: 20, 3: 20, 4: 20, 5: 20, 6: 20, 7: 21, 8: 21, 9: 20})"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_dev_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug_dropout_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_train_aug_norm},\n",
    "    y=y_train_aug,\n",
    "    batch_size=32,\n",
    "    num_epochs=100,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from digit_final/model.ckpt-4000\n",
      "INFO:tensorflow:Saving checkpoints for 4001 into digit_final/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.046797678, step = 4001\n",
      "INFO:tensorflow:global_step/sec: 264.294\n",
      "INFO:tensorflow:loss = 0.000934153, step = 4101 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.105\n",
      "INFO:tensorflow:loss = 0.03070413, step = 4201 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.893\n",
      "INFO:tensorflow:loss = 0.005239717, step = 4301 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.907\n",
      "INFO:tensorflow:loss = 0.0116049675, step = 4401 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.348\n",
      "INFO:tensorflow:loss = 0.0016865698, step = 4501 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.498\n",
      "INFO:tensorflow:loss = 0.0021787176, step = 4601 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.513\n",
      "INFO:tensorflow:loss = 0.00015165872, step = 4701 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.42\n",
      "INFO:tensorflow:loss = 0.0006335682, step = 4801 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.139\n",
      "INFO:tensorflow:loss = 0.0057921275, step = 4901 (0.301 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into digit_final/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0001366562.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7fc2245c7208>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_aug_dropout_classifier.train(\n",
    "    input_fn=train_aug_dropout_input_fn,\n",
    "    steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev_resized_norm = X_dev_resized / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev_nohe = distinct_encoding(Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-07-25-15:39:39\n",
      "INFO:tensorflow:Restoring parameters from digit_final/model.ckpt-5000\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-25-15:39:39\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.9752475, global_step = 5000, loss = 0.117541224\n",
      "{'accuracy': 0.9752475, 'loss': 0.117541224, 'global_step': 5000}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and print results\n",
    "eval_dropout_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_dev_resized_norm},\n",
    "    y=y_dev_nohe,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_results = digit_aug_dropout_classifier.evaluate(input_fn=eval_dropout_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the first training process the evaluation accuracy already beats 95%. By repeating the training process another 3 times we're able to increase this to 97.52 %. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model\n",
    "Let's see how the model is performing on data it has not seen yet. Since we used the development set for - well - development, it's highly likely we've been secretly overfitting to reduce the error rate on that set. Now it's time to put this to the test and get a good estimation on how well - or poor - we might perform in the real world of digit classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial Predictions\n",
    "First let's check out the prediction process on some sample data. We'll be using three digits from the training set and go through the prediction pipeline. This is the same function that will interface with any image data a user will input to the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_examples = [2566, 1999, 345]\n",
    "pred_data = X_train_aug_norm[list_of_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": pred_data},\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = digit_aug_dropout_classifier.predict(pred_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from digit_final/model.ckpt-5000\n",
      "Class: 3 - Probabilities: \n",
      "0 (0.0 %) 1 (0.0 %) 2 (0.0 %) 3 (100.0 %) 4 (0.0 %) 5 (0.0 %) 6 (0.0 %) 7 (0.0 %) 8 (0.0 %) 9 (0.0 %) \n",
      "Class: 2 - Probabilities: \n",
      "0 (0.0 %) 1 (0.0 %) 2 (100.0 %) 3 (0.0 %) 4 (0.0 %) 5 (0.0 %) 6 (0.0 %) 7 (0.0 %) 8 (0.0 %) 9 (0.0 %) \n",
      "Class: 8 - Probabilities: \n",
      "0 (0.14 %) 1 (0.0 %) 2 (0.0 %) 3 (0.01 %) 4 (0.0 %) 5 (0.0 %) 6 (0.0 %) 7 (0.0 %) 8 (95.67 %) 9 (4.18 %) \n"
     ]
    }
   ],
   "source": [
    "for pred in pred_results:\n",
    "    print ('Class: {} - Probabilities: '.format(pred['class']))\n",
    "    output_str = ''\n",
    "    for a, b in enumerate(pred['probabilities']):\n",
    "        output_str += str(a) + ' (' + str(round(b * 100., 2)) + ' %) '\n",
    "    print (output_str)\n",
    "    #print (pred['class'], pred['probabilities'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a quick sanity check that we're predicting the correct digits again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 8\n"
     ]
    }
   ],
   "source": [
    "for example in list_of_examples:\n",
    "    print_number_and_image(X_train_aug, y_train_aug, example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202, 256, 256, 1)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll resize and normalize the test set as well. For the application to work well we need to incorporate this pre-processing step into the pipeline for new images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rvbin/.virtualenvs/digits_classifier/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/rvbin/.virtualenvs/digits_classifier/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "X_test_resized = resize(X_test)\n",
    "X_test_resized_norm = X_test_resized / 255.\n",
    "X_test_resized_norm = X_test_resized_norm.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode y labels from one-hot-encoding to a distinct representation of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_nohe = distinct_encoding(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check that X and y data matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: [5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_number_and_image(X_test_resized_norm, Y_test_nohe, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-07-25-16:03:59\n",
      "INFO:tensorflow:Restoring parameters from digit_final/model.ckpt-5000\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-25-16:03:59\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.9653465, global_step = 5000, loss = 0.18451256\n",
      "{'accuracy': 0.9653465, 'loss': 0.18451256, 'global_step': 5000}\n"
     ]
    }
   ],
   "source": [
    "test_dropout_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": X_test_resized_norm},\n",
    "    y=Y_test_nohe,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "test_results = digit_aug_dropout_classifier.evaluate(input_fn=test_dropout_input_fn)\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 96.53% accuracy on the test set. That's quite the result given we started off with only 1010 images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Pre-Trained Model\n",
    "In case you were wondering how to train an existing model with new data. Here is the gist of it. It's essentially just loading the last checkpoint and funnels new training data into the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_unseen_example(test_img = 'images/handtest/3.png'):\n",
    "    im = Image.open(test_img)\n",
    "    im.thumbnail((28,28), Image.ANTIALIAS)\n",
    "    test_img_arr = np.array(im)[:,:,3]\n",
    "    test_img_right_format = np.zeros(shape=(28,28,1))\n",
    "    test_img_right_format[:,:,0] = test_img_arr\n",
    "    test_img_right_format = test_img_right_format.astype(np.float32)\n",
    "    return test_img_right_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = get_new_unseen_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for single images we need to make sure that the \n",
    "# format matches the architecture (1, 28, 28, 1) - (# images, size, size, channel)\n",
    "new_X = np.zeros(shape=(1,28,28,1))\n",
    "new_X[0,:,:,:] = new_image\n",
    "new_X = new_X.astype(np.float32)\n",
    "new_X = new_X / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc2612cf978>"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(new_X[0, :,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need a label to train with as well. In the application this information comes from a drop-down menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_Y = np.zeros(shape=(1, 1), dtype=int)\n",
    "new_Y[0] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": new_X},\n",
    "    y=new_Y,\n",
    "    batch_size=1,  # because we're inputting one image\n",
    "    num_epochs=4,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from digit_final/model.ckpt-5000\n",
      "INFO:tensorflow:Saving checkpoints for 5001 into digit_final/model.ckpt.\n",
      "INFO:tensorflow:loss = 4.76836e-06, step = 5001\n",
      "INFO:tensorflow:Saving checkpoints for 5004 into digit_final/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6.198864e-06.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7fc2228374a8>"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.train(\n",
    "    input_fn=train_new_input_fn,\n",
    "    steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
